---
title: "I can't be parsed, mate"
author: Matt Dray
date: '2023-03-03'
slug: getparsedata
categories:
  - code
  - tutorial
tags:
  - lintr
  - lobstr
  - magrittr
  - pipe
  - r
draft: no
---

<div class="figure">
<img src="/post/2023-02-28-getparsedata_files/handegg.png" alt="An American football quarterback about to pass the ball. He has the R logo on his shirt. Text above says 'pass the ball', text below is R code reading 'parse(text = 'the('ball')')'. The format is a 'deep-fried', highly pixellated meme where the centre of the iumage bloats out. A wide-eyed, smiling and crying emoji is in the corner." width="100%"/>
<p class="caption">Image by <a href="https://pixabay.com/users/keithjj-2328014/">Keith Johnston</a> from <a href="https://pixabay.com">Pixabay</a>. Deep fried by Matt Dray.[^fry]</p>
</div>

# tl;dr

R is capable of reading R code. Obviously. You can use `getParseData(parse())` to see what's going on. A very naive intro.

# At an imparse

There's many things that delight me about R coding.[^train] One meta thing I like is the idea that R has to recognise the code that you give it as... R code.

For example, does `x<-1` mean 'x is less than minus-one'? Hm, actually R recognises `<-` as a 'left-assignment operator'—a special 'token'—that gives the name `x` the value of `1`. Subtle, but important.

Another example: the tokens `<-` and `=` have an equivalent role in `x <- 1` and `x = 1`. For style reasons, you'll probably want to replace `=` with `<-`.[^down] But don't just 'find and replace' because `=` is context dependent. Consider:

```{r eval=FALSE}
x = subset(mtcars, subset = carb == 8)
```

Here, `=` is used to assign (`=`), to set a function argument (`=`) and as part of the equivalence operator (`==`). Oof.

How can a mere human understand this better?

# Parsed tense

The cool ('cool') thing is that R gives you tools to be able to see the world as R sees it. 

This is sometimes called 'static code analysis', in that you can interrogate the code for syntax errors _before_ it executes. Packages like [{lintr}](https://lintr.r-lib.org/) can even help tidy up ('lint') your code by adjusting or replacing the tokens.[^renkun]

I've used this approach before to:

* [create the {r2eng} package](https://www.rostrum.blog/2020/11/14/hello-r2eng/), which matches tokens against words so an expression can be translated to English (e.g. `<-` is matched to the word 'gets')
* [write an RStudio addin that auto-labels closing parentheses](https://www.rostrum.blog/2021/08/31/add-biscuits/) with the name of the function they belong to (known cutely as a 'biscuit')
* [identify and destroy files that contain equals assignment](https://www.rostrum.blog/2021/03/13/assign/) (`x = 1`), rather than the superior assignment arrow (`x <- 1`)

How might you tinker about with this yourself? Read on for a quickstart.

# Parse the parcel

I'll talk about two main functions: `parse()` and `getParseData()`, which are both part of base R.

You can pass a string of R code to `parse()` for it to be recognised as an 'expression'. Let's use the equals-rich `subset()` example from above.

```{r}
code_str <- "x = subset(mtcars, subset = carb == 8)"
code_expr <- parse(text = code_str)
code_expr
class(code_expr)
```

So the string is recognised as R code at this point, which will allow us to break it down into its individual tokens. You could jump ahead here and just `eval()`uate this expression object. 

```{r}
eval(code_expr)
x
```

As a result, the dataframe `x` is now in our environment and, as expected, contains only rows of the `mtcars` that have 8 `carb`uretors.[^carb]

So we have the power to delay code execution, like some kind of wizard. Jeepers! That's great, but now lets pick apart the frozen expression into its constituent tokens. This is where `getParseData()` comes in.

The function takes an expression object as the input and returns a dataframe with one token per row and several columns of handy information related to positioning and the relatedness between the tokens.

For now I'm going to simplify the output to show only the units of `text` that have been recognised as tokens, along with the name that R gives to each `token` under the hood (e.g. `<-` is recognised as `LEFT_ASSIGN`).[^tokens]

```{r}
code_parsed <- getParseData(parse(text = code_str, keep.source = TRUE))
code_parsed[code_parsed$text != "", c("text", "token")]
```

Oh neato, so you can see `=` is indeed recognised as the token `EQ_ASSIGN` ('equals assign'), `=` as `EQ_SUB` (equals in the context of supplying function arguments) and `==` as in `EQ` (the equivalence operator).

If you're wondering, the `keep.source = TRUE` bit was needed to encourage `parse()` to return its output, which is a necessary step within this non-interactive blog post.

# Parseltongue

Want to take a look at the tokens in a given string of R code yourself? You can use this little function that contains `parse()` and `getParseData()` and returns you the simplified dataframe I showed above if `simplify = TRUE`, otherwise it gives the full read out.[^ex] 

```{r}
parse_out <- function(string, simplify = TRUE) {
  p <- parse(text = string, keep.source = TRUE)
  pd <- getParseData(p)
  if (simplify) {
    keep_cols <- c("token", "text")
    pd <- pd[pd$text != "", keep_cols]
  }
  pd
}
```

So you could use it like:

```{r}
parse_out(
  "mean(CO2[CO2$Plant == 'Qn1', CO2$uptake]) -> mean_uptake"
)
```

<div class="tip"> `r fontawesome::fa("exclamation-circle")` <b>Update</b>

Since I wrote this post, it's become possible to [include editable R blocks in a rendered Quarto document](https://github.com/coatless/quarto-webr), which can be run in the browser thanks to [WebR](https://docs.r-wasm.org/webr/latest/)(!). [I've made a quick demo](https://webr-parse-test.netlify.app/) and [post](https://www.rostrum.blog/2023/03/16/webr-quarto/) so you can play around with a simplified version of the parsing function above.

</div>

# Lateral parse

I'll leave you with another interesting thing that shows you the inner workings of R, which you might not realise as you run your code. We can look at how the code is actually executed, not just the tokens that it's composed of.

Consider how the {magrittr} pipe `%>%` is used. Here I've slightly adjusted the input to filter for 6 and 8 `carb`uretors; you'll see why in a second.

```{r}
parse_out("mtcars %>% subset(carb %in% c(6, 8))")
```

Okay yeah, `%>%` is recognised as a token called `SPECIAL` between the left-hand side of `mtcars` and the right-hand side of `subset(carb %in% c(6, 8))`. Notice also that `%in%` is also recognised as `SPECIAL`. 

In fact, this is how R recognises ['infix operators'](https://adv-r.hadley.nz/functions.html?q=infix%20operator#infix-functions) that are bound by percent symbols. This is some special syntactical magic that lets you put the function name _between_ two arguments. So `x %>% head` is equivalent to `` `%>%`(mtcars, head) ``. Perhaps `SPECIAL` instead of a more specific name because infix operators can be created on the fly?

If `%>%` is `SPECIAL`, how do you think the base pipe is recognised in this simpler example?

```{r}
parse_out("mtcars |> head()")
```

Not that surprising: it's recognised as `PIPE` and not a `SPECIAL`, since it's a proper base R token in its own right ([as of R v4.1](https://www.rostrum.blog/2022/06/01/try-r/)) .

Okay, so we've seen how R parses these tokens, what about how it actually executes the code? One way to see this is to look at an 'abstract syntax tree' with [the {lobstr} package](https://lobstr.r-lib.org/).[^lobstr] A 'tree' to show the nested structure of code and variables and so on.

```{r}
library(lobstr)    # install from CRAN
library(magrittr)  # install from CRAN
ast(mtcars %>% head())
```

Yeah, like I said: `x %>% head()` is ultimately executed by R like a normal function (block symbol in the output from `ast()` above), in the form `` `%>%`(mtcars, head) ``. You can see how the `` `%>%` `` is a parent to `mtcars` and `head()` below it.

So the same happens for the base pipe, right?

```{r}
ast(mtcars |> head())
```

Surprise! `mtcars |> head` is not executed like `` `|>`(mtcars, head) ``. It's literally executed like `head(mtcars)`. The base pipe is so special because it's baked right into the R source code as a separate type of token that is recognised to have a job distinct from a basic `SPECIAL`. This should make it a little faster to run compared to `%>%` as well.

# Parse away

Well, 'cool' I guess. Now it's up to you: you can either parse on this knowledge, or leave it in the parsed.[^end]

---
<details><summary>Session info</summary>
```{r eval=TRUE, sessioninfo, echo=FALSE}
sessioninfo::session_info()
```
</details>

[^fry]: You too [can use R to deep fry a meme](https://www.rostrum.blog/2021/11/07/deepfry/).
[^train]: Things that I'm sure are quite trivial to gatekeepers. I learnt minimal amounts of R to help me wrangle ecological data and 'do statistics'. I'm not a computer scientist, nor was I trained as a programmer. 
[^down]: Of course, I'm not mentioning right assignment (`->`) here, nor the plucky upstart of [down-asignment](https://www.rostrum.blog/2022/06/07/assign-down/), which is certain to be the future for assignment in R.
[^tokens]: You can [see a list of these with English translations](https://github.com/wch/r-source/blob/0ee550ff68f22b8a1807377e728f99f2775cc43c/src/main/gram.y#L2312-L2350) in Winston Chang's GitHub copy of R's source code. So `NUM_CONST` is 'numeric constant', for example.
[^carb]: Not `carb`ohydrates. 'Non-car people' should take a look at the 'Format' section of `?mtcars`. I mean, `drat` means 'rear axle ratio', what?
[^lobstr]: A package with one of my favourite names and [hex logos](https://lobstr.r-lib.org/logo.png). The 'str' is from 'structure', as in 'the structure of code'. The logo is a lobster snipping apart the 'lob' from 'str' text. I mean, \*(lobster) chef's kiss\* on that one. `r emoji::emoji("lobster")`
[^end]: Yeah, I'm hoping you didn't read this far. Obviously I didn't know how to end the post, sorry.
[^ex]: An exercise for the reader is to alter this function to accept an R script file rather than a string (hint: `parse()` takes a `file` argument).
[^renkun]: You may also enjoy [a post by Kun Ren](https://renkun.me/2020/11/08/using-parse-data-to-analyze-r-code/) about how this approach is useful for static analysis in [the {languageserver} package](https://github.com/REditorSupport/languageserver), which is a handy download for using R in VS Code.