---
title: Apple Health and Nike Run Club with {xml2}
author: Matt Dray
date: '2021-03-23'
slug: xml-health
categories:
  - code
  - tutorial
tags:
  - apple
  - health
  - r
  - running
  - tidyverse
  - xml2
draft: no
---

```{r setup, include=FALSE}
# https://bookdown.org/yihui/rmarkdown-cookbook/hook-truncate.html
# save built-in output hook then set a new output hook to truncate text output
hook_output <- knitr::knit_hooks$get("output")
knitr::knit_hooks$set(output = function(x, options) {
  if (!is.null(n <- options$out.lines)) {
    x <- xfun::split_lines(x)
    if (length(x) > n) {
      # truncate the output
      x <- c(head(x, n), "....\n")
    }
    x <- paste(x, collapse = "\n")
  }
  hook_output(x, options)
})
```

<div class="figure">
<img src="/post/2021-03-07-xml-health_files/barcode.png" alt="A one-dimensional plot of days represented by vertical lines, with run distance coloured on a scale of white to black." width="100%"/>
<p class="caption">Run barcode: one year of runs, darker bands are longer distances.</p>
</div>

# tl;dr

You can export your [Apple Health](https://www.apple.com/uk/ios/health/) data as an XML file. This includes workouts linked from other apps, like [Nike Run Club](https://www.nike.com/nrc-app). I used the R packages [{xml2}](https://xml2.r-lib.org/index.html) and [the tidyverse](https://www.tidyverse.org/) to extract and clean my step counts and running activity.

# App storage

My healthcare provider peeks at [the Apple Health app](https://www.apple.com/uk/ios/health/) and rewards me if I meet daily step-count targets. I know my usual pattern of steps has been disrupted since the start of COVID-19 lockdowns, [which began in the UK a year ago today](https://fullfact.org/health/coronavirus-lockdown-hancock-claim/).

To keep the step counter ticking over, I took up a new hobby on lockdown day one: running. I've recorded this activity on [the Nike Run Club app](https://www.nike.com/nrc-app), which I've linked to Apple Health.

I've in excess of 99 problems and at least two of them are related specifically to these health data:

1. I don't think my healthcare supplier is rewarding my step counts correctly and I need evidence[^duncan]
1. It's not easy to get data out of the Nike Run Club app for further analysis

Luckily, you can export the data---which is stored locally on your iPhone---including any workouts linked from other apps. It's provided as XML, which is a sensible, structured storage format, but not necessarily that familiar to the general R user.

This post looks at how to extract the data of interest and do something useful with it.

# Warm up

To export activity data from the Health app (iOS 14.4):

1. Open the Health app and tap your icon in the top right corner
1. Scroll down and tap 'Export All Health Data'
1. Tap 'Export' in the pop-up and the sharing tray will slide up for you to choose where to send the data

You'll get a zipped folder containing two XML files, `export_cda.xml` and `export.xml`, the latter of which contains your data. I stored and unzipped my folder locally for the purposes of this post.

```{r unzip}
temp <- tempdir()
unzip(zipfile = "~/Downloads/export.zip", exdir = temp)
```

My unzipped folder was about 140 MB and contained about 5 years of data. 

We'll also need a few R packages. [The {xml2} package](https://xml2.r-lib.org/index.html)[^xml2] is on CRAN and has the tools you need to read and reshape XML files. It may be familiar if you've ever done any webscraping with R.[^scrape]

We'll also iterate to accumulate with [the {purrr} package](https://purrr.tidyverse.org/) and do the ol' wrangle-jangle with some [other tidyverse packages](https://www.tidyverse.org/). 

```{r, library, message=FALSE}
library(xml2)       # read and wrangle XML
library(tidyverse)  # {purrr}, {dplyr}, {ggplot2}, {forcats}
library(lubridate)  # date/time handling
```

# X-tract

The aptly named `xml2::read_xml()` function will let you read your `export.xml` file. 

```{r, read}
xml_in <- read_xml(file.path(temp, "apple_health_export/export.xml"))
```

Here's a truncated view of the file's structure:

```{r print-xml, out.lines=7}
xml_in
```

The object has the class `xml_document`. You can see metadata in the first few rows and then you can see the actual data is stored in a series of 'nodes'. Each record is an individual entry in our activity log and has attributes like `type` (e.g. step count), `sourceName` (i.e. the device name) and `unit` (e.g. a count).

We're interested in extracting data from two types of node:

* `Record` for the step counts, as previewed above
* `Workouts`, which is where the Nike Run Club app data is stored

You can extract specific parts of an XML file by reference to their [xpaths](https://www.w3schools.com/xml/xpath_intro.asp), which are special regex-like strings that point to specific places in the document. The function `xml2::xml_find_all()` takes an xpath and returns the matching information.

We need only supply the simple high-level xpaths `//Record` and `//Workouts` for our needs. The forward slashes [read like](https://www.w3schools.com/xml/xpath_syntax.asp) 'select all the nodes in the document with the following name'.

Once extracted, we can get the attributes---like `type`, `sourceName`, etc---of each node using `xml2::xml_attr()`.

# Step to it

So, let's grab all the 'record' nodes and preview the first one.

```{r rcds-find}
records <- xml_find_all(xml_in, "//Record")
records[[1]]
```

Each record is a single 'bout' of activity as perceived by the app. You can see the first record is a step count from my phone on 21 June 2015, which lasted about two minutes and consisted of 28 steps.

For my purposes I only care about three attributes: the date[^time], the type of activity and the associated value. We can pass a named vector of each attribute to `xml2::xml_attr()` using `purrr::map_dfr()` to collate the output into a tidy rectangle.

```{r rcds-attrs}
records_df <- map_dfr(  # rowbind to dataframe
  c(date = "creationDate", type = "type", steps = "value"),
  ~xml_attr(records, .x)
)

glimpse(records_df)  # preview
```

So what `type` of activity has been logged in the `Record` nodes?

```{r rcds-types}
pull(distinct(records_df, type))
```

I'm interested in step counts, so I'll isolate `HKQuantityTypeIdentifierStepCount`, convert the date to datetime class and then summarise the number of steps per day. 

```{r rcds-wrangle}
records_out <- records_df %>% 
  filter(type == "HKQuantityTypeIdentifierStepCount") %>%
  mutate(date = as.Date(date), steps = as.integer(steps)) %>%
  group_by(date) %>%
  summarise(steps = sum(steps), .groups = "drop") %>% 
  mutate(
    points = case_when(
      steps > 12500 ~ 8L, steps > 10000 ~ 5L, steps > 7000 ~ 3L,
      TRUE ~ 0L
    )
  )

glimpse(records_out)
```

I also created a new column that generates a 'points' value that my healthcare provider assigns to meeting certain step-count thresholds. Now I, tiny David, can sling this evidence into the eye of the behemoth cyclops that is my healthcare provider.

I recommend checking first if the data look sensible, because my highest step count was apparently `r format(max(records_out$steps), big.mark = ",")`. I don't recall walking to Chicago and back to London on that day.

## On a walkabout

There's so many ways you could investigate the step count data, like how frequency changes by day of the week or time of year, for example. 

Here's a quick exploration: how did my step-count frequency change in the year up to 23 March 2020---the announcement of the UK's first lockdown---and in the year since?

```{r wo-plot, fig.alt='Side-by-side histograms of step counts before and after lockdown. Before lockdown, a bimodal distribution with peaks at about 3 and 10 km steps. After lockdown, a big peak at about 1 km and a peak at about 6 km with a tail to about 20 km.'}
records_out %>% 
  mutate(
    covid_year = case_when(
      date >= "2020-03-23" & date < "2021-03-23" ~ "Year post-lockdown",
      date >= "2019-03-23" & date < "2020-03-23" ~ "Year pre-lockdown", 
      TRUE ~ NA_character_
    )
  ) %>% 
  filter(!is.na(covid_year)) %>% 
  ggplot() + 
  geom_histogram(aes(steps / 1000), binwidth = 1) + 
  facet_grid(~fct_rev(covid_year)) +
  labs(x = "Steps (thousands)", y = "Frequency") +
  theme_minimal()
```

Ha, not a surprise, but interesting to see it visually: there's been a far higher proportion of days with a very small number of steps in the lockdown year. The second peak of the bimodal distribution has also fallen to a lower value with a more gradual tail. This is understandable: I used to walk on parts of my commute and lunchtimes, whereas my lockdown days have involved running or basically nothing.

# Jog on

Now let's look at the year's worth of running data from the `Workout` nodes of the XML.

```{r wo-find}
workouts <- xml_find_all(xml_in, "//Workout")
workouts[[1]]
```

The attributes are slightly different for workouts compared to records. This time I care about the activity type (just runs), the date, the distance and the time taken. Unfortunately there isn't any data on split times in this file, which means I can't calculate record times, nor is there other detail like altitude gained.

```{r wo-attrs}
workouts_df <- map_dfr(
  c(date = "creationDate", type = "workoutActivityType",
    km = "totalDistance", dur = "duration"),
  ~xml_attr(workouts, .x)
) 

glimpse(workouts_df)
```

We can do a bit of light wrangling to convert 'decimal minutes' to seconds, compute a rough pace, and round the values for readability. I used `lubridate::seconds_to_period()` to generate a `period`-class value that presents the data in days, hours, minutes and seconds.

```{r wo-wrangle}
workouts_out <- workouts_df %>% 
  filter(type == "HKWorkoutActivityTypeRunning", km > 1) %>% 
  mutate(
    date = as.Date(date),
    across(c(dur, km), as.numeric), dur = round(dur, 3)
  ) %>% 
  separate(col = dur, into = c("mins", "mins_dec"), sep = "\\.") %>% 
  transmute(
    date, km,
    s = (as.numeric(mins) * 60) + ((as.numeric(mins_dec) / 1000) * 60),
    mins = seconds_to_period(round(s)),
    avg_pace = seconds_to_period(round(s / km)),
    s = round(s), km = round(km, 2)
  )

glimpse(workouts_out)
```

## High-vis apparel

The data are now quite rich and there's many ways to explore it. As a starter, here's some basic summaries for the year to 23 March 2021:

```{r wo-summarise}
workouts_out %>% 
  summarise(
    `Total runs` = n(),
    `Total distance (km)` = round(sum(km)),
    `Total time` = seconds_to_period(sum(s)),
    `Days per run` = round((max(date) - min(date)) / `Total runs`, 1),
    `Best average pace` = seconds_to_period(min(round(s / km))),
    `Total runs of 5 to 10 km` = nrow(filter(., km >= 5 & km < 10)),
    `Total runs of 10 to 21.1 km` = nrow(filter(., km >= 10 & km < 21.1)),
    `Total runs of over 21.1 km` = nrow(filter(., km > 21.1))
  ) %>% 
  mutate(across(everything(), as.character)) %>% 
  pivot_longer(everything(), names_to = "Summary", values_to = "Value") %>% 
  knitr::kable()
```

In terms of visualisation, I'm interested in what my pattern of run distance looks like. The code below produces plots for run distances by date (top left), cumulative distance by date (bottom left), and a histogram of run distances in 1 km bins (right).

```{r wo-plots, fig.alt='Three plots: distance over time scatterplot, cumulative distance over time line chart, and a histogram of run distance. Patterns show high frequency of 5 and 10 km runs and consistency of run days over time.'}
p1 <- ggplot(workouts_out) + 
  geom_point(aes(date, km), shape = 1) +
  labs(x = "", y = "Distance (km)") +
  theme_light()

p2 <- workouts_out %>% 
  mutate(km_cum = cumsum(km)) %>% 
  ggplot() +
  geom_line(aes(date, km_cum)) +
  labs(x = "", y = "Cumulative distance (km)") +
  theme_light()

p3 <- ggplot(workouts_out) +
  geom_histogram(aes(km), binwidth = 1) +
  labs(x = "Distance (1 km bins)", y = "Frequency") +
  theme_light()

library(patchwork)  # easy plot layouts
(p1 / p2) | p3
```

You can see I started with a lot of 5 km runs in April and May 2020, before branching out to 10 km or more. I've been pretty consistent in running every two or three days and that's reflected in the chart of cumulative distance. The histogram shows that most runs have been just above 5 km, with another peak just above 10 km. That makes sense: I intentionally set out to run at least these distances.

Another idea is that you you could use [the {calendR} package](https://github.com/R-CoderDotCom/calendR) to plot a calendar of your activity[^duncan]. Or you could do something more abstract: here's a 'run barcode' with a line per run for the full year. The darker the line, the further the distance travelled.

```{r wo-barcode, fig.height=1, fig.width=10, fig.alt='A one-dimensional plot of days represented by vertical lines, with run distance coloured on a scale of white to black.'}
run_days <- left_join(
  tibble(date = as_date(ymd("2020-03-23"):ymd("2021-03-22"))),
  workouts_out %>% 
    filter(date >= "2020-03-23" & date < "2021-03-23") %>%
    group_by(date) %>% summarise(km = sum(km), .groups = "drop"),
  by = "date"
) %>% replace_na(list(run = 0))

par(mar = rep(0, 4))
image(matrix(run_days$km), col = grey.colors(11, 0.8, 0))
box(col = "white")
```

A few things stick out to me when scanning this barcode. The three black bands are the half-marathons; the white space (i.e. no runs) after the first of these indicates the rest my knees needed afterwards. There's a thick grey band after halfway, which is when I tried to run seven days in a row (the app is gamified and you get a special badge for doing that). You can also see how the pattern was more regular at the start, but I've since settled into a routine of just trying to fit in three runs and about 25 km per week.

# Cool down

So the premise was quite simple: download your Apple Health data, read the XML file, extract the nodes of interest, wrangle lightly and present it. I've only done a basic exploration of the data, but there's so much more you could do.

After starting this post, I noticed that [Mark Koester has written an in-depth post](http://www.markwk.com/data-analysis-for-apple-health.html) about Apple Health data, with a focus on Python code for achieving a similar goal. It notes third-party tools like [QS Access](https://apps.apple.com/gb/app/qs-access/id920297614) for extracting data into a friendlier CSV format, for example.

If you're an R user and you're interested in running, [Colin Fay has organised a GitHub-based system](https://twitter.com/_ColinFay/status/1373704738626273280?s=20) for holding yourself accountable in ramping up to runs of 5 km. A new session starts on 5 April.

I also noticed that [Huong Ly Tong will be giving a talk](https://twitter.com/RLadiesBrisbane/status/1373854449777602566) at R Ladies Brisbane later in the month, with a focus on using R to analyse step count data.

It'll be interesting to revisit this in another year's time to see how a 'return to normality' (whatever that means) might impact these patterns of activity.

---
<details><summary>Session info</summary>
```{r sessioninfo, echo=FALSE}
sessioninfo::session_info()
```
</details>

[^duncan]: In this vein, you can also [use your Google Maps data to convince the church to marry you](https://nacnudus.github.io/duncangarmonsway/posts/2019-04-22-get-me-to-the-church-on-time-with-r-spatial/), as per Duncan Garmonsway. 
[^xml2]: '2' because it's a binding to [libxml2](http://xmlsoft.org/), but perhaps also because it's the spiritual successor to [{XML}](https://CRAN.R-project.org/package=XML), which is R's veteran package for XML handling.
[^scrape]: For example, see previous posts about [travelling the NBA](https://www.rostrum.blog/2018/12/24/nba-travel/) and [polite webscraping](https://www.rostrum.blog/2019/03/04/polite-webscrape/).
[^time]: Luckily, I live at +0000, so no time-related data wrangling is required for me.
[^duncan2]: Another reference to [Duncan's post]  (https://nacnudus.github.io/duncangarmonsway/posts/2019-04-22-get-me-to-the-church-on-time-with-r-spatial/).