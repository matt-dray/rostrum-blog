---
title: Hit your reproducibility {targets}
author: Matt Dray
date: '2020-09-27'
slug: targets-dsfest
categories:
  - code
  - event
  - tutorial
tags:
  - conference
  - drake
  - r
  - reproducibility
  - targets
draft: no
---

<div class="figure">
<img src="https://media.giphy.com/media/Qw4X3FLJ9IqHAJorAEU/giphy.gif" alt="A beaver pushing mud up against a dam." width="75%"/>
<p class="caption">An excuse to use the dam good (lol) `beavers1` data ([Nature on PBS via Giphy](https://giphy.com/gifs/pbsnature-beaver-Qw4X3FLJ9IqHAJorAEU/links))</p>
</div>

# tl;dr

I spoke at the [UK Government Data Science Festival](https://dataingovernment.blog.gov.uk/2020/09/25/government-data-science-festival-2020/) about [Will Landau](https://wlandau.github.io/)'s R package [{targets}](https://wlandau.github.io/targets/) for workflow reproducibility.

You can [jump to the embedded slides](#slides) below.

# {targets}

Reproducibility is an important part of any data analysis. Will people be able to re-run your code from scratch on a different machine without you present?

R has lots of solutions for making your analysis reproducible, but one thing that gets overlooked is the reproducibility of the workflow itself. In other words, the interdependencies between functions, file and objects and the order in which they run.

<div class="figure">
<img src="/post/2020-09-25-targets-dsfest_files/targets-hex.png" alt="The hexagon logo for the targets package, which shows images of a folder, histogram and bar chart joined consecutively by arrows." width="30%"/>
</div>

The R package {targets} ‘remembers’ these relationships. In short,{targets} makes sure that only the impacted objects are re-run when you update your analysis. This means you don’t have to recreate everything from scratch each time.

A very basic overview of using {targets}:

1. Write a pipeline script
1. Inspect the pipeline (including visually)
1. Execute the pipeline
1. Change stuff
1. Go to 2

With functions:

1. `tar_script()` creates a `_targets.R` file, which is where you declare you write functions and options and create your targets with `tar_targets()`, declaring the pipeline with `tar_pipeline()`
1. `tar_manifest()` lets you check the configuration of your targets
1. `tar_visnetwork` visualises your pipeline as a graph network
1. `tar_make()` executes your pipeline, which caches outputs and metadata in a `_targets/` directory that can be read from with `tar_read()` and `tar_load()` (you could use )
1. `tar_outdated()` prints any targets that need to be updated following any changes to other targets, after which you can reinspect your pipeline and re-make it

You can find [an example workflow in the {targets} manual](https://wlandau.github.io/targets-manual/walkthrough.html) and many other resources are [listed in the {targets} README on GitHub](https://github.com/wlandau/targets/blob/master/README.md).

# Slides and code {#slides}

The slides[^xaringan] are embedded below. The presentation considers the need for workflow reproducibility followed by a small, contrived demo of the {targets} package in action: a short pipeline for rendering an R Markdown report with a plot and a table.[^beaver]

```{r slides, echo=FALSE}
xaringanExtra::embed_xaringan(
  "https://matt-dray.github.io/targets-dsfest/",
  ratio = "4:3",
)
```

You can also open the slides [in a dedicated browser window](https://matt-dray.github.io/targets-dsfest/#1). Press <kbd>P</kbd> for presenter notes, <kbd>O</kbd> for a slide overview and <kbd>F</kbd> for fullscreen.

The presentation's source is in [a GitHub repo](https://github.com/matt-dray/targets-dsfest) that also contains {targets}-related files and scripts for running the example seen in the slides. See [the 'Demo code' section of the README](https://github.com/matt-dray/targets-dsfest#readme) for details.

It wasn't possible in this talk to go into greater depth on other excellent {targets} features like parallel computing and branching, but you can read about them in [the {targets} manual](https://wlandau.github.io/targets-manual/).

# But... {drake}?

You may have noticed I have cunningly plagiarised myself by re-using slides from [a presentation to Bioinformatics London](https://www.rostrum.blog/2020/01/31/reprobioinformatics/) in January 2020.

<div class="figure">
<img src="/post/2020-09-25-targets-dsfest_files/drake-hex.png" alt="The hexagon logo for the drake package, which shows a hammer with a brain inside it." width="30%"/>
</div>

That presentation was about {drake}, another workflow reproducibility package by Will Landau. I also [wrote about the {drake} package as a tool](https://www.rostrum.blog/2019/07/23/can-drake-rap/) for the [Reproducible Analytical Pipelines](https://dataingovernment.blog.gov.uk/2017/03/27/reproducible-analytical-pipeline/) (RAP) movement in UK government.

So what's the difference between the two packages? In [Will's own words](https://wlandau.github.io/targets-manual/):

>years of community feedback [on {drake}] have exposed major user-side limitations regarding data management, collaboration, parallel efficiency, and pipeline archetypes

{drake} is the more mature package and certainly it works, but {targets} is designed to address certain {drake} issues that only became apparent with ongoing, large-scale user testing in the wild. While {targets} addresses these problems, it's worth noting that it's still in development (v0.0.0.9002 at time of writing) and changes may be implemented that limit the usefulness of this post in future.

Ultimately it's up to the user to decide which package they'd prefer to use for now, but {targets} looks to be the future for workflow reproducibility implemented within the R ecosystem. 

[^xaringan]: Created with [{xaringan}](https://slides.yihui.org/xaringan/#1) by [Yihui Xie](https://yihui.org/) with some bonus features via [{xaringanExtra}](https://pkg.garrickadenbuie.com/xaringanExtra/#/) by [Garrick Aden-Buie](https://www.garrickadenbuie.com/).
[^beaver]: Using the excellent [`beaver1` and `beaver2` datasets](https://stat.ethz.ch/R-manual/R-devel/library/boot/html/beaver.html).