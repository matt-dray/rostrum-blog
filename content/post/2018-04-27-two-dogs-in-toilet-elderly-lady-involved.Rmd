---
title: TWO DOGS IN TOILET ELDERLY LADY INVOLVED
author: Matt Dray
date: '2018-04-27'
slug: two-dogs-in-toilet-elderly-lady-involved
categories:
  - R
  - dataviz
tags:
  - dplyr
  - stringr
  - leaflet
  - sf
  - datatable
  - animals
---

<span style="color:lightgray">Matt Dray</span>

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  error = FALSE,
  warning = FALSE,
  message = FALSE
)
```

# TL;DR

Animals get stuck in weird places. Oh, and the `sf` package in R can be used for coordinate reprojection prior to interactive mapping with `leaflet`.

# The problem

I often work with data that has coordinates; usually a [eastings and northings](https://en.wikipedia.org/wiki/Easting_and_northing). I need to convert these to [latitude](https://en.wikipedia.org/wiki/Latitude) and [longitude](https://en.wikipedia.org/wiki/Longitude) for interactive mapping using the [`leaflet`](https://rstudio.github.io/leaflet/) package in [R](https://www.r-project.org/about.html). What might be an easy way to do this?

I'm going to demo the `sf` package, show how to reproject coordinates, work with points and polygon data, make an interactive map with `leaflet` and do a bonus bit of webscraping.

Mostly I wrote this post for my own reference and to learn a bit more about using the `sf` package. Feel free to discuss or suggest anything in the comments.

# Special features

The [`sf` ('special features') package](https://github.com/r-spatial/sf) from [Edzer Pebesma](https://orcid.org/0000-0001-8049-7069) has a series of classes and methods for spatial data. The package is becoming popular because simple feature access is a widely-used multi-platform [ISO standard](https://www.iso.org/standard/40114.html) and the package supports the popular [tidy data](http://r4ds.had.co.nz/tidy-data.html) paradigm and can be integrated with [tidyverse operations](https://www.tidyverse.org/). This and more was [spelled out by Pebesma in a post](https://edzer.github.io/UseR2017/) from [UseR! 2017](https://user2017.brussels/).

What does this mean for [`sp`](https://cran.r-project.org/web/packages/sp/index.html), the go-to package for spatial analysis in R? Well, its not going anywhere for now. You can get an opinion on whether you [should learn `sf` or `sp` for spatial R programming](http://www.seascapemodels.org/rstats/2018/03/23/should-I-learn-sp-or-sf.html) from Seascape Models (spoiler: `sf`, but maybe both if you can).

# Some data

## Animal rescues

I've got an interesting example dataset that contains eastings and northings: [animal rescue incidents](https://data.london.gov.uk/dataset/animal-rescue-incidents-attended-by-lfb/resource/e6211993-9ea2-4ed4-9378-7344653e9c31) attended by the [London Fire Brigade](https://www.london-fire.gov.uk/incidents/) `r emo::ji("fire_engine")` from the excellent [London Data Store](https://data.london.gov.uk/). In their words:

> The London Fire Brigade attends a range of non-fire incidents (which we call 'special services'). These 'special services' include assistance to animals that may be trapped or in distress.

This is pertinent because a pigeon fell down our chimney recently.

<img src="/post/2018-04-27-two-dogs-in-toilet-elderly-lady-involved_files/mr-chimney.jpg" alt="The back end of the trapped pigeon visible through a vent hole in our chimeny breast" width="100%">

## Clean the data

First download the data from [the datastore](https://data.london.gov.uk/dataset/animal-rescue-incidents-attended-by-lfb/resource/e6211993-9ea2-4ed4-9378-7344653e9c31) as a CSV file. Then we can read it and clean the column names.

```{r read_data}
library(readr)  # for reading data
library(dplyr)  # data manipulation and pipes (%>%)
library(janitor)  # cleaning and misc functions
library(lubridate)  # dealing with dates

# read the csv
rescue <- readr::read_csv("data/lfb-animal-rescue.csv")

# replace rogue '£' with blank
names(rescue) <- iconv(names(rescue), to = "ASCII", sub = "")

# more cleaning
rescue <- rescue %>% 
  rename(IncidentNominalCost = `IncidentNominalCost()`) %>%  # no brackets
  mutate(DateTimeOfCall = lubridate::ymd_hms(DateTimeOfCall))  # convert type

# preview
glimpse(rescue) 
```

So each row is an 'incident' to which the brigade were called and there are various columns for when, what, and where.

## Explore the data

This post isn't about the dataset, but it's worth having a closer look at it. I've added an interactive table below so you can filter and search for incidents, creatures, locations and the nominal cost of the callout.

```{r datatable, echo=FALSE}
# interactive table
rescue %>%
  mutate(  # allows for dropdown on interactive table
    Animal = as.factor(AnimalGroupParent),
    Borough = as.factor(Borough),
    IncidentNominalCost = ifelse(
      test = IncidentNominalCost == "NULL",
      yes = NA,
      no = as.numeric(IncidentNominalCost)
    )
  ) %>% 
  select(
    Incident = FinalDescription,
    Animal,
    Borough,
    `Nominal cost (£)` = IncidentNominalCost
  ) %>% 
  DT::datatable(
    filter = "top",
    rownames = FALSE,
    options = list(
      autoWidth = TRUE,
      pageLength = 5
    )
  )
```
<p>
<p>
Obviously there are plenty of cats up trees, but there's so much more. Some of the more unique entries are:

> DOG WITH JAW TRAPPED IN MAGAZINE RACK `r paste(emo::ji("dog"), emo::ji("newspaper"))`

> SWAN IN DISTRESS `r paste(emo::ji("duck"), emo::ji("confounded"))`

> FERRET STUCK IN LIFT SHAFT [ferret emoji needed]

And of course:

> TWO DOGS IN TOILET ELDERLY LADY INVOLVED `r paste(emo::ji("dog2"), emo::ji("poodle"), emo::ji("toilet"), emo::ji("older_woman"))`

Hmmm. `r emo::ji("thinking_face")`

# Get spatial with `sf`

## Points data

Each incident in aour data is a point in space with an X and Y coordinate. It's currently eastings and northings, but we want to transform it to latitude and longitude.

### 'sf' class and reprojection

A  [Coordinate Reference System](https://en.wikipedia.org/wiki/Spatial_reference_system) (CRS) is required to project geographic entities -- points, polygons, etc -- onto a surface. There are many systems for doing this, from local to global, each with its own CRS code. This isn't a post about geography and projections, but you can read more in the CRS chapter of [rspatial.org](http://rspatial.org/spatial/rst/6-crs.html).

First we convert the our dataframe-class object an 'sf' class object using the `st_as_sf` function, which readies it for spatial analysis. We simply provide arguments that point to the columns containing the coordinates and the CRS code for that projection system. 

We can then use the `st_transform()` function to convert our projection system from eastings and northings to to latitude and longitude. 

```{r}
library(sf)

rescue_sf <- rescue %>% 
  sf::st_as_sf(
    coords = c("Easting_rounded", "Northing_rounded"),  # columns with coordinates
    crs = 27700  # coordinate reference system code for eastings/northings
  ) %>% 
  sf::st_transform(crs = 4326)  # the coord ref system code for latlong

print(rescue_sf)
```

So what happened more specifically? Our eastings and northings were combined with `st_as_sf()` into a two element [list-column](https://jennybc.github.io/purrr-tutorial/ls13_list-columns.html) called `geometry` with data type `sfc_POINT`. Our new sf-class object also contains some metadata detailing the geometry type -- `POINTS` in our case -- and the projection system of the coordinate data, which we converted to latlong with the `st_transform()` function.

### Tidyverse manipulation

As mentioned, one advantage of using `sf` is that sf-class objects use the [tidy data](http://r4ds.had.co.nz/tidy-data.html) paradigm that allows for use of the [tidyverse](https://www.tidyverse.org/). Som eusers may prefer this relative to the 'Spatial Points Data Frame' (SPDF) class that is produced by the `sp` package for points data. SPDFs are an [S4 class](http://adv-r.had.co.nz/S4.html), which means they have 'slots' of data, coordinates, etc.

In the code chunk above I used pipes to pass the `rescue` dataframe to `st_as_sf()` and then to `st_transform()`. You can also use `dplyr` functions like `filter()` on your sf-class object.

```{r dplyr}
filtered_rescue_sf <- rescue_sf %>%
  dplyr::filter(
    AnimalGroupParent %in% c("Dog", "Cat", "Bird"),  # just these animals
    DateTimeOfCall > lubridate::ymd("2017-01-01") &
      DateTimeOfCall < lubridate::ymd("2017-12-31")  # 2017 only
  )
```

We can also use the `st_coordinates()` function to extract the XY (latitude and longitude) coordinates from the column containing our `sf` point geometry. This means we can have separate columns for the latitude and longitude, as well as our list-column.

```{r st_coordinates}
# extract coordinates into two-column dataframe
rescue_coords <- as.data.frame(st_coordinates(filtered_rescue_sf))

# bind these to rescue dataset
filtered_rescue_sf <- dplyr::bind_cols(filtered_rescue_sf, rescue_coords)

# preview
head(filtered_rescue_sf)
```

## Polygons data

### Read and convert GeoJSON

While we're messing around with the `sf` package we can investigate polygons by adding in the borders for each of the London boroughs from a [GeoJSON](http://geojson.org/) file.

First, read [Local Authority District](https://en.wikipedia.org/wiki/Districts_of_England) (LADs) data directly from the [Open Geography Portal](http://geoportal.statistics.gov.uk/) and then use the `st_as_sf()` function to make the conversion from the sp class to the sf class.

This means our polygon dataset is a tidy dataframe with the polygon information stored as `MULTIPOLYGON` type in a list-column with as many elements as required to draw each polygon (e.g. a square requires four sets of XY points that can be joined together). The outcome is very similar to what we had for our points data.

```{r geojson}
library(geojsonio)  # for working with geojson files

# read geojson from the web (local authorities)
lad_json <- geojsonio::geojson_read(
  x = "https://opendata.arcgis.com/datasets/fab4feab211c4899b602ecfbfbc420a3_4.geojson",
  what = "sp"  # spatial class
)

# convert to sf
lad_sf <- sf::st_as_sf(lad_json)

# preview
head(lad_sf)
```

### Scrape London borough list

But which of these LADs are London boroughs? We can extract a vector of the boroughs from Wikipedia using the [`rvest`](http://blog.rstudio.com/2014/11/24/rvest-easy-web-scraping-with-r/) package and use it to filter our data. The CSS selector used in the `html_nodes()` function below can be extracted using the very handy [SelectorGadget tool](http://selectorgadget.com/).

```{r boroughs}
library(rvest)  # scraping webpages
library(xml2)  # parsing XML

# read the webpage
wiki <- xml2::read_html("https://en.wikipedia.org/wiki/List_of_London_boroughs")

# get borough names
boroughs <- wiki %>% 
  rvest::html_nodes(css = "td:nth-child(1) > a") %>%
  rvest::html_text() %>% 
  tolower()

# filter the sf for london boroughs
boroughs_sf <- lad_sf %>% 
  mutate(lad17nm = tolower(lad17nm)) %>% 
  dplyr::filter(lad17nm %in% boroughs)

# preview
head(boroughs_sf)
```

# Map it

So now we can plot the data. The `addPolygons()` function accepts each `MULTIPOLYGON` in the list-column of our London boroughs dataset.  The `addMarkers()` function accepts the POINTS-type list-column to plot each point at the latitude and longitude specified.

This is a very simple map for now. You can:

* zoom with the `+` and `-` buttons or scroll with your mouse wheel
* click and drag to move the map
* click the points to get a pop-up showing more information
* hover over a borough to highlight it and show a label

```{r leaflet}
library(leaflet)  # for interactive mapping

# put the map together
leaflet::leaflet(boroughs_sf) %>% 
  leaflet::addTiles() %>%
  leaflet::addPolygons(  # add London borough boundaries
    label = ~tools::toTitleCase(lad17nm),  # label on hover
    color = "black",  # boundary colour
    weight = 2,  # boundary thickness
    opacity = 1,  # fully opaque lines
    fillOpacity = 0.2,  # mostly transparent
    highlightOptions = highlightOptions(
      color = "white",  # turn boundary white on hover
      weight = 2,  # same as polygon boundary
      bringToFront = TRUE  # overlay the highglight
    )
  ) %>% 
  leaflet::addAwesomeMarkers( # add incident points
    lng = filtered_rescue_sf$X, lat = filtered_rescue_sf$Y,
    icon = leaflet::awesomeIcons(
      library = "ion",  # from this icon library
      icon = "ion-android-alert",  # use this icon
      iconColor = "white",  # colour it white
      # colour by animal
      markerColor = case_when(  # different colours for each
        filtered_rescue_sf$AnimalGroupParent == "Dog" ~ "red",
        filtered_rescue_sf$AnimalGroupParent == "Cat" ~ "blue",
        filtered_rescue_sf$AnimalGroupParent == "Bird" ~ "black"
      )
    ),
    popup = ~paste0(  # display this information on click
      "<b>Animal</b>: ", filtered_rescue_sf$AnimalGroupParent, "<br>",
      "<b>Incident</b>: ", filtered_rescue_sf$FinalDescription, "<br>",
      "<b>Date</b>: ", filtered_rescue_sf$DateTimeOfCall, "<br>",
      "<b>Borough</b>: ", filtered_rescue_sf$Borough, "<br>",
      "<b>Nominal cost</b>: £", filtered_rescue_sf$IncidentNominalCost
    )
  )
```
<p>
<p>
Okay cool, we get a simple map of London with borough boundaries and markers showing incidents in 2017, with a different colour for each of three selected animal groups (red = dog, blue = cat, black = bird).

# And remember

My main advice? Keep an eye on your pets. _And consider covering your chimney_.

# Further reading on `sf`

* [Geocomputation with R](https://bookdown.org/robinlovelace/geocompr/) by Robin Lovelace, Jakub Nowosad and Jannes Muenchow
* [Introduction to GIS with R: Spatial data with the sp and sf packages](https://www.jessesadler.com/post/gis-with-r-intro/) and [Geocoding with R: Using ggmap to geocode and map historical data](https://www.jessesadler.com/post/geocoding-with-r/) by Jesse Sadler
* [Spatial analysis pipelines with simple features in R](http://walkerke.github.io/2016/12/spatial-pipelines/) from Kyle Walker Data

# R session information

```{r sessionInfo}
sessionInfo()
```